{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODdPMjQCiqKKKR3LtXvFNW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/likarajo/resenetx/blob/main/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Lm6GQXOy8c"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# LOGISTICS\n",
        "#\n",
        "#    Rajarshi Chattopadhyay\n",
        "#    RXC170010\n",
        "#\n",
        "# DESCRIPTION\n",
        "#\n",
        "#    Image classification in PyTorch for ImageNet reduced to 100 classes and\n",
        "#    down sampled such that the short side is 64 pixels and the long side is\n",
        "#    >= 64 pixels\n",
        "#\n",
        "#    This script achieved a best accuracy of ??.??% on epoch ?? with a learning\n",
        "#    rate at that point of ?.????? and time required for each epoch of ~ ??? s\n",
        "#\n",
        "# INSTRUCTIONS\n",
        "#\n",
        "#    1. Go to Google Colaboratory: https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "#    2. File - New Python 3 notebook\n",
        "#    3. Cut and paste this file into the cell (feel free to divide into multiple cells)\n",
        "#    4. Runtime - Run all\n",
        "#\n",
        "# NOTES\n",
        "#\n",
        "#    0. For a mapping of category names to directory names see:\n",
        "#       https://gist.github.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57\n",
        "#\n",
        "#    1. The original 2012 ImageNet images are down sampled such that their short\n",
        "#       side is 64 pixels (the other side is >= 64 pixels) and only 100 of the\n",
        "#       original 1000 classes are kept.\n",
        "#\n",
        "#    2. Build and train a RegNetX image classifier modified as follows:\n",
        "#\n",
        "#       - Set stride = 1 (instead of stride = 2) in the stem\n",
        "#       - Replace the first stride = 2 down sampling building block in the\n",
        "#         original network by a stride = 1 normal building block\n",
        "#       - The fully connected layer in the decoder outputs 100 classes instead\n",
        "#         of 1000 classes\n",
        "#\n",
        "#       The original RegNetX takes in 3x224x224 input images and generates Nx7x7\n",
        "#       feature maps before the decoder, this modified RegNetX will take in\n",
        "#       3x56x56 input images and generate Nx7x7 feature maps before the decoder.\n",
        "#       For reference, an implementation of this network took ~ 112 s per epoch\n",
        "#       for training, validation and checkpoint saving on Sep 27, 2020 using a\n",
        "#       free GPU runtime in Google Colab.\n",
        "#\n",
        "################################################################################"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBJDqEv-O5cr"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# IMPORT\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "import torch.nn       as     nn\n",
        "import torch.optim    as     optim\n",
        "from   torch.autograd import Function\n",
        "\n",
        "# torch utils\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "# additional libraries\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import time\n",
        "import math\n",
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4CPm9CPO-LY"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# PARAMETERS\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# data\n",
        "DATA_DIR_1        = 'data'\n",
        "DATA_DIR_2        = 'data/imagenet64'\n",
        "DATA_DIR_TRAIN    = 'data/imagenet64/train'\n",
        "DATA_DIR_TEST     = 'data/imagenet64/val'\n",
        "DATA_FILE_TRAIN_1 = 'Train1.zip'\n",
        "DATA_FILE_TRAIN_2 = 'Train2.zip'\n",
        "DATA_FILE_TRAIN_3 = 'Train3.zip'\n",
        "DATA_FILE_TRAIN_4 = 'Train4.zip'\n",
        "DATA_FILE_TRAIN_5 = 'Train5.zip'\n",
        "DATA_FILE_TEST_1  = 'Val1.zip'\n",
        "DATA_URL_TRAIN_1  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train1.zip'\n",
        "DATA_URL_TRAIN_2  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train2.zip'\n",
        "DATA_URL_TRAIN_3  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train3.zip'\n",
        "DATA_URL_TRAIN_4  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train4.zip'\n",
        "DATA_URL_TRAIN_5  = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Train5.zip'\n",
        "DATA_URL_TEST_1   = 'https://github.com/arthurredfern/UT-Dallas-CS-6301-CNNs/raw/master/Data/Val1.zip'\n",
        "DATA_BATCH_SIZE   = 512\n",
        "DATA_NUM_WORKERS  = 4\n",
        "DATA_NUM_CHANNELS = 3\n",
        "DATA_NUM_CLASSES  = 100\n",
        "DATA_RESIZE       = 64\n",
        "DATA_CROP         = 56\n",
        "DATA_MEAN         = (0.485, 0.456, 0.406)\n",
        "DATA_STD_DEV      = (0.229, 0.224, 0.225)\n",
        "\n",
        "DATA_CLASS_NAMES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# model\n",
        "# add model parameters here\n",
        "D = 13\n",
        "w0 = 24\n",
        "wa = 36\n",
        "wm = 2.5\n",
        "b = 1\n",
        "g = 8\n",
        "q = 1\n",
        "\n",
        "# training\n",
        "# add training parameters here\n",
        "TRAINING_LR_MAX          = 0.001\n",
        "TRAINING_LR_INIT_SCALE   = 0.01\n",
        "TRAINING_LR_INIT_EPOCHS  = 5\n",
        "TRAINING_LR_FINAL_SCALE  = 0.01\n",
        "#TRAINING_LR_FINAL_EPOCHS = 55\n",
        "TRAINING_LR_FINAL_EPOCHS = 2 # uncomment for a quick test\n",
        "TRAINING_NUM_EPOCHS = TRAINING_LR_INIT_EPOCHS + TRAINING_LR_FINAL_EPOCHS\n",
        "TRAINING_LR_INIT = TRAINING_LR_MAX*TRAINING_LR_INIT_SCALE\n",
        "TRAINING_LR_FINAL = TRAINING_LR_MAX*TRAINING_LR_FINAL_SCALE\n",
        "\n",
        "# file\n",
        "# add file parameters here\n",
        "FILE_NAME = 'ResNetX.pt'\n",
        "FILE_SAVE = 0\n",
        "FILE_LOAD = 0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZJBm29mPCya"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# DATA\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# create a local directory structure for data storage\n",
        "if (os.path.exists(DATA_DIR_1) == False):\n",
        "    os.mkdir(DATA_DIR_1)\n",
        "if (os.path.exists(DATA_DIR_2) == False):\n",
        "    os.mkdir(DATA_DIR_2)\n",
        "if (os.path.exists(DATA_DIR_TRAIN) == False):\n",
        "    os.mkdir(DATA_DIR_TRAIN)\n",
        "if (os.path.exists(DATA_DIR_TEST) == False):\n",
        "    os.mkdir(DATA_DIR_TEST)\n",
        "\n",
        "# download data\n",
        "if (os.path.exists(DATA_FILE_TRAIN_1) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_1, DATA_FILE_TRAIN_1)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_2) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_2, DATA_FILE_TRAIN_2)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_3) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_3, DATA_FILE_TRAIN_3)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_4) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_4, DATA_FILE_TRAIN_4)\n",
        "if (os.path.exists(DATA_FILE_TRAIN_5) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_5, DATA_FILE_TRAIN_5)\n",
        "if (os.path.exists(DATA_FILE_TEST_1) == False):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_1, DATA_FILE_TEST_1)\n",
        "\n",
        "# extract data\n",
        "with zipfile.ZipFile(DATA_FILE_TRAIN_1, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
        "with zipfile.ZipFile(DATA_FILE_TRAIN_2, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
        "with zipfile.ZipFile(DATA_FILE_TRAIN_3, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
        "with zipfile.ZipFile(DATA_FILE_TRAIN_4, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
        "with zipfile.ZipFile(DATA_FILE_TRAIN_5, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TRAIN)\n",
        "with zipfile.ZipFile(DATA_FILE_TEST_1, 'r') as zip_ref:\n",
        "    zip_ref.extractall(DATA_DIR_TEST)\n",
        "\n",
        "# transforms\n",
        "transform_train = transforms.Compose([transforms.RandomResizedCrop(DATA_CROP), transforms.RandomHorizontalFlip(p=0.5), transforms.ToTensor(), transforms.Normalize(DATA_MEAN, DATA_STD_DEV)])\n",
        "transform_test  = transforms.Compose([transforms.Resize(DATA_RESIZE), transforms.CenterCrop(DATA_CROP), transforms.ToTensor(), transforms.Normalize(DATA_MEAN, DATA_STD_DEV)])\n",
        "\n",
        "# data sets\n",
        "dataset_train = torchvision.datasets.ImageFolder(DATA_DIR_TRAIN, transform=transform_train)\n",
        "dataset_test  = torchvision.datasets.ImageFolder(DATA_DIR_TEST,  transform=transform_test)\n",
        "\n",
        "# data loader\n",
        "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=DATA_BATCH_SIZE, shuffle=True,  num_workers=DATA_NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "dataloader_test  = torch.utils.data.DataLoader(dataset_test,  batch_size=DATA_BATCH_SIZE, shuffle=False, num_workers=DATA_NUM_WORKERS, pin_memory=True, drop_last=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtLaMklfPGEP"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# NETWORK BUILDING BLOCK\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# Downsample\n",
        "class Downsample(nn.Module):\n",
        "\n",
        "    # initialization\n",
        "    def __init__(self, Ni, No, stride):\n",
        "\n",
        "        # parent initialization\n",
        "        super(Downsample, self).__init__()\n",
        "\n",
        "        self.conv_1x1 = nn.Conv2d(Ni, No, kernel_size=1, stride=stride, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(No)\n",
        "\n",
        "    # forward path\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = self.bn(self.conv_1x1(x))\n",
        "\n",
        "        return y\n",
        "\n",
        "# Stem\n",
        "class Stem(nn.Module):\n",
        "\n",
        "    # initialization\n",
        "    def __init__(self, No, Ni=3):\n",
        "\n",
        "        # parent initialization\n",
        "        super(Stem, self).__init__()\n",
        "\n",
        "        self.conv_3x3 = nn.Conv2d(Ni, No, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(No)\n",
        "\n",
        "    # forward path\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = nn.functional.relu(self.bn(self.conv_3x3(x)))\n",
        "\n",
        "        return y\n",
        "\n",
        "# Head\n",
        "class Head(nn.Module):\n",
        "\n",
        "    # initialization\n",
        "    def __init__(self, Ni, classes):\n",
        "\n",
        "        # parent initialization\n",
        "        super(Head, self).__init__()\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.f_out = nn.Linear(Ni, classes) \n",
        "\n",
        "    # forward path\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = self.avg_pool(x)\n",
        "        y = torch.flatten(y, 1)\n",
        "        y = self.f_out(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "# X block\n",
        "class XBlock(nn.Module):\n",
        "\n",
        "    # initialization\n",
        "    def __init__(self, Ni, No, bottleneck_ratio, group_size, stride=1, se_ratio=0):\n",
        "\n",
        "        # parent initialization\n",
        "        super(XBlock, self).__init__()\n",
        "\n",
        "        # add your code here\n",
        "        # operations needed to create a parameterized XBlock\n",
        "        Bo = Ni // bottleneck_ratio\n",
        "        g = Bo // group_size\n",
        "\n",
        "        # 1x1 Conv bottleneck block\n",
        "        self.conv1_1x1 = nn.Conv2d(Ni, Bo, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(Bo)\n",
        "\n",
        "        # 3x3 Conv group block (~ResNeXt)\n",
        "        self.conv2_3x3 = nn.Conv2d(Bo, Bo, kernel_size=3, bias=False, stride=stride, padding=1, groups=g)\n",
        "        self.bn2 = nn.BatchNorm2d(Bo)\n",
        "\n",
        "        # Downsample block if stride=2\n",
        "        self.downsample = Downsample(Ni, No, stride) if (stride==2 or Ni!=No) else None\n",
        "\n",
        "        # 1x1 Conv block\n",
        "        self.conv3_1x1 = nn.Conv2d(Bo, No, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(No)\n",
        "\n",
        "    # forward path\n",
        "    def forward(self, x):\n",
        "\n",
        "        # add your code here\n",
        "        # tie together the operations to create a parameterized XBlock\n",
        "\n",
        "        y = self.conv1_1x1(x)\n",
        "        y = self.bn1(y)\n",
        "        y = nn.functional.relu(y)\n",
        "\n",
        "        y = self.conv2_3x3(y)\n",
        "        y = self.bn2(y)\n",
        "        y = nn.functional.relu(y)\n",
        "\n",
        "        y = self.conv3_1x1(y)\n",
        "        y = self.bn3(y)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        else:\n",
        "            residual = x\n",
        "\n",
        "        y += residual\n",
        "        y = nn.functional.relu(y)\n",
        "\n",
        "        # return\n",
        "        return y\n",
        "\n",
        "# Layer\n",
        "class Layer(nn.Module):\n",
        "\n",
        "    # initialization\n",
        "    def __init__(self, Ni, d, w, bottleneck_ratio, g, se_ratio, isLayer1):\n",
        "\n",
        "        # parent initialization\n",
        "        super(Layer, self).__init__()\n",
        "\n",
        "        self.layers = []\n",
        "        for i in range(d):\n",
        "            if isLayer1:\n",
        "                stride = 1\n",
        "            else:\n",
        "                stride = 2 if i==0 else 1\n",
        "            x_block = XBlock(Ni, w, bottleneck_ratio, g, stride, se_ratio)\n",
        "            self.layers.append(x_block)\n",
        "            Ni = w\n",
        "\n",
        "        self.layers = nn.Sequential(*self.layers)\n",
        "\n",
        "    # forward path\n",
        "    def forward(self, x):\n",
        "\n",
        "        y = self.layers(x)\n",
        "\n",
        "        return y"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkcUe7PBPJ2q"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# NETWORK\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# Generate model parameters\n",
        "def generate_parameters(D, w0, wa, wm, b, g, q):\n",
        "\n",
        "    # Equation 1\n",
        "    u = w0 + wa * np.arange(D) \n",
        "\n",
        "    # Equation 2 (rounded block size)\n",
        "    s = np.log(u / w0) / np.log(wm) \n",
        "    s = np.round(s)\n",
        "\n",
        "    # Equation 3 (widths divisible by 8)\n",
        "    w = w0 * np.power(wm, s) \n",
        "    w = np.round(w / 8) * 8\n",
        "\n",
        "    # Width and Depth lists\n",
        "    w, d = np.unique(w.astype(np.int), return_counts=True) \n",
        "\n",
        "    # Make width compatible with group sizes of the convolutional layers\n",
        "    gtemp = np.minimum(g, w//b)\n",
        "    w = (np.round(w // b / gtemp) * gtemp).astype(int) \n",
        "    g = np.unique(gtemp // b)[0]\n",
        "\n",
        "    return (w, d, b, g, q)\n",
        "\n",
        "\n",
        "# Model\n",
        "class Model(nn.Module):\n",
        "\n",
        "    # initialization\n",
        "    def __init__(self,\n",
        "                 data_num_channels,\n",
        "                 params, # include model parameters here\n",
        "                 data_num_classes):\n",
        "\n",
        "        # parent initialization\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # add your code here\n",
        "        # operations needed to create a modified RegNetX-200MF network\n",
        "        # use the parameterized XBlock defined to simplify this section\n",
        "\n",
        "        # Parameters\n",
        "        self.Ni = 32\n",
        "        self.num_layers = 4\n",
        "        self.w, self.d, self.b, self.g, self.se_ratio = params\n",
        "\n",
        "        # Stem\n",
        "        self.stem = Stem(self.Ni)\n",
        "\n",
        "        # Body with 4 layers of bottleneck residual blocks\n",
        "        self.body = []\n",
        "        for i in range(self.num_layers):\n",
        "            isLayer1 = True if i==0 else False\n",
        "            layer = Layer(self.Ni, self.d[i], self.w[i], self.b, self.g, self.se_ratio, isLayer1=isLayer1)\n",
        "            self.body.append(layer)\n",
        "            self.Ni = self.w[i]\n",
        "        self.body = nn.Sequential(*self.body)\n",
        "                \n",
        "        # Head with average pooling and linear activation for classification\n",
        "        self.head = Head(self.w[-1], data_num_classes)\n",
        "\n",
        "    # forward path\n",
        "    def forward(self, x):\n",
        "\n",
        "        # add your code here\n",
        "        # tie together the operations to create a modified RegNetX-200MF\n",
        "        y = self.stem(x)\n",
        "        y = self.body(y)\n",
        "        y = self.head(y)\n",
        "\n",
        "        # return\n",
        "        return y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC_wBP2kPNrG",
        "outputId": "1308ddc4-37d5-48da-de7e-c9124b145e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# get parameters\n",
        "params = generate_parameters(D, w0, wa, wm, b, g, q)\n",
        "\n",
        "# create model\n",
        "model = Model(DATA_NUM_CHANNELS,\n",
        "              params, # include model parameters here\n",
        "              DATA_NUM_CLASSES)\n",
        "\n",
        "# model visualization\n",
        "print(model)\n",
        "\n",
        "# model summary\n",
        "summary(model, input_size=(3, 56, 56))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (stem): Stem(\n",
            "    (conv_3x3): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (body): Sequential(\n",
            "    (0): Layer(\n",
            "      (layers): Sequential(\n",
            "        (0): XBlock(\n",
            "          (conv1_1x1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
            "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (downsample): Downsample(\n",
            "            (conv_1x1): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv3_1x1): Conv2d(32, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): Layer(\n",
            "      (layers): Sequential(\n",
            "        (0): XBlock(\n",
            "          (conv1_1x1): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=3, bias=False)\n",
            "          (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (downsample): Downsample(\n",
            "            (conv_1x1): Conv2d(24, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv3_1x1): Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): Layer(\n",
            "      (layers): Sequential(\n",
            "        (0): XBlock(\n",
            "          (conv1_1x1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (downsample): Downsample(\n",
            "            (conv_1x1): Conv2d(64, 152, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (bn): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv3_1x1): Conv2d(64, 152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): XBlock(\n",
            "          (conv1_1x1): Conv2d(152, 152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(152, 152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=19, bias=False)\n",
            "          (bn2): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3_1x1): Conv2d(152, 152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (2): XBlock(\n",
            "          (conv1_1x1): Conv2d(152, 152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(152, 152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=19, bias=False)\n",
            "          (bn2): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3_1x1): Conv2d(152, 152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): XBlock(\n",
            "          (conv1_1x1): Conv2d(152, 152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(152, 152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=19, bias=False)\n",
            "          (bn2): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3_1x1): Conv2d(152, 152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): Layer(\n",
            "      (layers): Sequential(\n",
            "        (0): XBlock(\n",
            "          (conv1_1x1): Conv2d(152, 152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(152, 152, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=19, bias=False)\n",
            "          (bn2): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (downsample): Downsample(\n",
            "            (conv_1x1): Conv2d(152, 376, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (bn): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (conv3_1x1): Conv2d(152, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): XBlock(\n",
            "          (conv1_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(376, 376, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=47, bias=False)\n",
            "          (bn2): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (2): XBlock(\n",
            "          (conv1_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(376, 376, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=47, bias=False)\n",
            "          (bn2): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (3): XBlock(\n",
            "          (conv1_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(376, 376, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=47, bias=False)\n",
            "          (bn2): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (4): XBlock(\n",
            "          (conv1_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(376, 376, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=47, bias=False)\n",
            "          (bn2): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (5): XBlock(\n",
            "          (conv1_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(376, 376, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=47, bias=False)\n",
            "          (bn2): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (6): XBlock(\n",
            "          (conv1_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2_3x3): Conv2d(376, 376, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=47, bias=False)\n",
            "          (bn2): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3_1x1): Conv2d(376, 376, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): Head(\n",
            "    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "    (f_out): Linear(in_features=376, out_features=100, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 56, 56]             864\n",
            "       BatchNorm2d-2           [-1, 32, 56, 56]              64\n",
            "              Stem-3           [-1, 32, 56, 56]               0\n",
            "            Conv2d-4           [-1, 32, 56, 56]           1,024\n",
            "       BatchNorm2d-5           [-1, 32, 56, 56]              64\n",
            "            Conv2d-6           [-1, 32, 56, 56]           2,304\n",
            "       BatchNorm2d-7           [-1, 32, 56, 56]              64\n",
            "            Conv2d-8           [-1, 24, 56, 56]             768\n",
            "       BatchNorm2d-9           [-1, 24, 56, 56]              48\n",
            "           Conv2d-10           [-1, 24, 56, 56]             768\n",
            "      BatchNorm2d-11           [-1, 24, 56, 56]              48\n",
            "       Downsample-12           [-1, 24, 56, 56]               0\n",
            "           XBlock-13           [-1, 24, 56, 56]               0\n",
            "            Layer-14           [-1, 24, 56, 56]               0\n",
            "           Conv2d-15           [-1, 24, 56, 56]             576\n",
            "      BatchNorm2d-16           [-1, 24, 56, 56]              48\n",
            "           Conv2d-17           [-1, 24, 28, 28]           1,728\n",
            "      BatchNorm2d-18           [-1, 24, 28, 28]              48\n",
            "           Conv2d-19           [-1, 64, 28, 28]           1,536\n",
            "      BatchNorm2d-20           [-1, 64, 28, 28]             128\n",
            "           Conv2d-21           [-1, 64, 28, 28]           1,536\n",
            "      BatchNorm2d-22           [-1, 64, 28, 28]             128\n",
            "       Downsample-23           [-1, 64, 28, 28]               0\n",
            "           XBlock-24           [-1, 64, 28, 28]               0\n",
            "            Layer-25           [-1, 64, 28, 28]               0\n",
            "           Conv2d-26           [-1, 64, 28, 28]           4,096\n",
            "      BatchNorm2d-27           [-1, 64, 28, 28]             128\n",
            "           Conv2d-28           [-1, 64, 14, 14]           4,608\n",
            "      BatchNorm2d-29           [-1, 64, 14, 14]             128\n",
            "           Conv2d-30          [-1, 152, 14, 14]           9,728\n",
            "      BatchNorm2d-31          [-1, 152, 14, 14]             304\n",
            "           Conv2d-32          [-1, 152, 14, 14]           9,728\n",
            "      BatchNorm2d-33          [-1, 152, 14, 14]             304\n",
            "       Downsample-34          [-1, 152, 14, 14]               0\n",
            "           XBlock-35          [-1, 152, 14, 14]               0\n",
            "           Conv2d-36          [-1, 152, 14, 14]          23,104\n",
            "      BatchNorm2d-37          [-1, 152, 14, 14]             304\n",
            "           Conv2d-38          [-1, 152, 14, 14]          10,944\n",
            "      BatchNorm2d-39          [-1, 152, 14, 14]             304\n",
            "           Conv2d-40          [-1, 152, 14, 14]          23,104\n",
            "      BatchNorm2d-41          [-1, 152, 14, 14]             304\n",
            "           XBlock-42          [-1, 152, 14, 14]               0\n",
            "           Conv2d-43          [-1, 152, 14, 14]          23,104\n",
            "      BatchNorm2d-44          [-1, 152, 14, 14]             304\n",
            "           Conv2d-45          [-1, 152, 14, 14]          10,944\n",
            "      BatchNorm2d-46          [-1, 152, 14, 14]             304\n",
            "           Conv2d-47          [-1, 152, 14, 14]          23,104\n",
            "      BatchNorm2d-48          [-1, 152, 14, 14]             304\n",
            "           XBlock-49          [-1, 152, 14, 14]               0\n",
            "           Conv2d-50          [-1, 152, 14, 14]          23,104\n",
            "      BatchNorm2d-51          [-1, 152, 14, 14]             304\n",
            "           Conv2d-52          [-1, 152, 14, 14]          10,944\n",
            "      BatchNorm2d-53          [-1, 152, 14, 14]             304\n",
            "           Conv2d-54          [-1, 152, 14, 14]          23,104\n",
            "      BatchNorm2d-55          [-1, 152, 14, 14]             304\n",
            "           XBlock-56          [-1, 152, 14, 14]               0\n",
            "            Layer-57          [-1, 152, 14, 14]               0\n",
            "           Conv2d-58          [-1, 152, 14, 14]          23,104\n",
            "      BatchNorm2d-59          [-1, 152, 14, 14]             304\n",
            "           Conv2d-60            [-1, 152, 7, 7]          10,944\n",
            "      BatchNorm2d-61            [-1, 152, 7, 7]             304\n",
            "           Conv2d-62            [-1, 376, 7, 7]          57,152\n",
            "      BatchNorm2d-63            [-1, 376, 7, 7]             752\n",
            "           Conv2d-64            [-1, 376, 7, 7]          57,152\n",
            "      BatchNorm2d-65            [-1, 376, 7, 7]             752\n",
            "       Downsample-66            [-1, 376, 7, 7]               0\n",
            "           XBlock-67            [-1, 376, 7, 7]               0\n",
            "           Conv2d-68            [-1, 376, 7, 7]         141,376\n",
            "      BatchNorm2d-69            [-1, 376, 7, 7]             752\n",
            "           Conv2d-70            [-1, 376, 7, 7]          27,072\n",
            "      BatchNorm2d-71            [-1, 376, 7, 7]             752\n",
            "           Conv2d-72            [-1, 376, 7, 7]         141,376\n",
            "      BatchNorm2d-73            [-1, 376, 7, 7]             752\n",
            "           XBlock-74            [-1, 376, 7, 7]               0\n",
            "           Conv2d-75            [-1, 376, 7, 7]         141,376\n",
            "      BatchNorm2d-76            [-1, 376, 7, 7]             752\n",
            "           Conv2d-77            [-1, 376, 7, 7]          27,072\n",
            "      BatchNorm2d-78            [-1, 376, 7, 7]             752\n",
            "           Conv2d-79            [-1, 376, 7, 7]         141,376\n",
            "      BatchNorm2d-80            [-1, 376, 7, 7]             752\n",
            "           XBlock-81            [-1, 376, 7, 7]               0\n",
            "           Conv2d-82            [-1, 376, 7, 7]         141,376\n",
            "      BatchNorm2d-83            [-1, 376, 7, 7]             752\n",
            "           Conv2d-84            [-1, 376, 7, 7]          27,072\n",
            "      BatchNorm2d-85            [-1, 376, 7, 7]             752\n",
            "           Conv2d-86            [-1, 376, 7, 7]         141,376\n",
            "      BatchNorm2d-87            [-1, 376, 7, 7]             752\n",
            "           XBlock-88            [-1, 376, 7, 7]               0\n",
            "           Conv2d-89            [-1, 376, 7, 7]         141,376\n",
            "      BatchNorm2d-90            [-1, 376, 7, 7]             752\n",
            "           Conv2d-91            [-1, 376, 7, 7]          27,072\n",
            "      BatchNorm2d-92            [-1, 376, 7, 7]             752\n",
            "           Conv2d-93            [-1, 376, 7, 7]         141,376\n",
            "      BatchNorm2d-94            [-1, 376, 7, 7]             752\n",
            "           XBlock-95            [-1, 376, 7, 7]               0\n",
            "           Conv2d-96            [-1, 376, 7, 7]         141,376\n",
            "      BatchNorm2d-97            [-1, 376, 7, 7]             752\n",
            "           Conv2d-98            [-1, 376, 7, 7]          27,072\n",
            "      BatchNorm2d-99            [-1, 376, 7, 7]             752\n",
            "          Conv2d-100            [-1, 376, 7, 7]         141,376\n",
            "     BatchNorm2d-101            [-1, 376, 7, 7]             752\n",
            "          XBlock-102            [-1, 376, 7, 7]               0\n",
            "          Conv2d-103            [-1, 376, 7, 7]         141,376\n",
            "     BatchNorm2d-104            [-1, 376, 7, 7]             752\n",
            "          Conv2d-105            [-1, 376, 7, 7]          27,072\n",
            "     BatchNorm2d-106            [-1, 376, 7, 7]             752\n",
            "          Conv2d-107            [-1, 376, 7, 7]         141,376\n",
            "     BatchNorm2d-108            [-1, 376, 7, 7]             752\n",
            "          XBlock-109            [-1, 376, 7, 7]               0\n",
            "           Layer-110            [-1, 376, 7, 7]               0\n",
            "AdaptiveAvgPool2d-111            [-1, 376, 1, 1]               0\n",
            "          Linear-112                  [-1, 100]          37,700\n",
            "            Head-113                  [-1, 100]               0\n",
            "================================================================\n",
            "Total params: 2,275,604\n",
            "Trainable params: 2,275,604\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.04\n",
            "Forward/backward pass size (MB): 28.28\n",
            "Params size (MB): 8.68\n",
            "Estimated Total Size (MB): 36.99\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY6dCnbQPUha"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# ERROR AND OPTIMIZER\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# add your code here\n",
        "# define the error criteria and optimizer\n",
        "\n",
        "# Error criterion (softmax cross entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcQTaXYDPWlV",
        "outputId": "140b518b-295f-4de0-d49c-f25595186738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# TRAINING\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# add your code here\n",
        "# perform network training, validation and checkpoint saving\n",
        "# see previous examples in the Code directory\n",
        "\n",
        "# Learning rate schedule\n",
        "def lr_schedule(epoch):\n",
        "\n",
        "    # staircase\n",
        "    # lr = TRAINING_LR_MAX*math.pow(TRAINING_LR_SCALE, math.floor(epoch/TRAINING_LR_EPOCHS))\n",
        "\n",
        "    # linear warmup followed by cosine decay\n",
        "    if epoch < TRAINING_LR_INIT_EPOCHS: # Linear warmpup\n",
        "        lr = (TRAINING_LR_MAX - TRAINING_LR_INIT)*(float(epoch)/TRAINING_LR_INIT_EPOCHS) + TRAINING_LR_INIT\n",
        "    else: # Cosine decay\n",
        "        lr = (TRAINING_LR_MAX - TRAINING_LR_FINAL)*max(0.0, math.cos(((float(epoch) - TRAINING_LR_INIT_EPOCHS)/(TRAINING_LR_FINAL_EPOCHS - 1.0))*(math.pi/2.0))) + TRAINING_LR_FINAL\n",
        "\n",
        "    return lr\n",
        "\n",
        "# enable data parallelization for multi GPU systems\n",
        "if (torch.cuda.device_count() > 1):\n",
        "    model = nn.DataParallel(model)\n",
        "print('Using {0:d} GPU(s)'.format(torch.cuda.device_count()), flush=True)\n",
        "\n",
        "# specify the device as the GPU if present with fallback to the CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# transfer the network to the device\n",
        "model.to(device)\n",
        "print(\"Model transfered to device: \", device)\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "# model loading\n",
        "if FILE_LOAD == 1:\n",
        "    checkpoint = torch.load(FILE_NAME)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "\n",
        "print('Training started...')\n",
        "for epoch in range(start_epoch, TRAINING_NUM_EPOCHS):\n",
        "\n",
        "    # initialize training state\n",
        "    model.train()\n",
        "    training_loss = 0.0\n",
        "    num_batches = 0\n",
        "    \n",
        "    # set learning rate for the epoch\n",
        "    for g in optimizer.param_groups:\n",
        "        g['lr'] = lr_schedule(epoch)\n",
        "\n",
        "    # cycle through the train set\n",
        "    for data in dataloader_train:\n",
        "\n",
        "        # extract a batch of data and move it to the appropriate device\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # reset parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # backward propagation\n",
        "        loss.backward()\n",
        "\n",
        "        # weight update\n",
        "        optimizer.step()\n",
        "\n",
        "        # update training stats\n",
        "        training_loss = training_loss + loss.item()\n",
        "        num_batches = num_batches + 1\n",
        "\n",
        "    # initialize test state\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    \n",
        "    # no gradient/weight update needed\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # cycle through the test set\n",
        "        for data in dataloader_test:\n",
        "\n",
        "            # extract a batch of data and move it to the appropriate device\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # update test stats\n",
        "            test_correct = test_correct + (predicted == labels).sum().item()\n",
        "            test_total = test_total + labels.size(0)\n",
        "\n",
        "    # update epoch stats\n",
        "    avg_loss = (training_loss/num_batches)/DATA_BATCH_SIZE\n",
        "    acc = 100.0*test_correct/test_total\n",
        "\n",
        "    print('Epoch {0:2d} lr = {1:8.6f} avg_loss = {2:8.6f} accuracy = {3:5.2f}'.format(epoch, lr_schedule(epoch), avg_loss, acc))\n",
        "\n",
        "    # Checkpointing\n",
        "    if FILE_SAVE == 1:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()\n",
        "        }, FILE_NAME)\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 0 GPU(s)\n",
            "Model transfered to device:  cpu\n",
            "Training started...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3f1a32d96f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-3b236941ec8f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# tie together the operations to create a modified RegNetX-200MF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-99af9e5ce9c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-99af9e5ce9c3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 175) is killed by signal: Killed. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX2UZVO6gjOf"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# TEST\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# initialize test state\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total   = 0\n",
        "\n",
        "# initialize class stats\n",
        "class_correct = list(0. for i in range(DATA_NUM_CLASSES))\n",
        "class_total   = list(0. for i in range(DATA_NUM_CLASSES))\n",
        "\n",
        "print('Testing...')\n",
        "# no gradient/weight update needed\n",
        "with torch.no_grad():\n",
        "\n",
        "    # cycle through the test set\n",
        "    for data in dataloader_test:\n",
        "\n",
        "        # extract a batch of data and move it to the appropriate device\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # update test set stats\n",
        "        test_total = test_total + labels.size(0)\n",
        "        test_correct = test_correct + (predicted == labels).sum().item()\n",
        "\n",
        "        # update class stats\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(labels.size(0)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "# test set stats\n",
        "acc = 100.0*test_correct/test_total\n",
        "print('Accuracy of test set = {0:5.2f}'.format(acc))\n",
        "print('')\n",
        "\n",
        "# class stats\n",
        "for i in range(len(DATA_CLASS_NAMES)):\n",
        "    acc = 100.0*class_correct[i]/class_total[i]\n",
        "    print('Accuracy of {0:5s} = {1:5.2f}'.format(DATA_CLASS_NAMES[i], acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5gfjdHwjDT8"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# DISPLAY\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# set to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# extract a batch of data\n",
        "data_iterator  = iter(dataloader_test)\n",
        "inputs, labels = data_iterator.next()\n",
        "\n",
        "# images and ground truth labels\n",
        "images    = torchvision.utils.make_grid(inputs)/2 + 0.5\n",
        "np_images = images.numpy()\n",
        "plt.imshow(np.transpose(np_images, (1, 2, 0)))\n",
        "print('Ground truth = ', ' '.join('%5s' % DATA_CLASS_NAMES[labels[j]] for j in range(DATA_BATCH_SIZE)))\n",
        "\n",
        "# move it to the appropriate device\n",
        "inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "# forward pass\n",
        "outputs      = model(inputs)\n",
        "\n",
        "# prediction\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# predicted labels\n",
        "print('Predicted    = ', ' '.join('%5s' % DATA_CLASS_NAMES[predicted[j]] for j in range(DATA_BATCH_SIZE)))\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}